---
title: "Mixup Training for Generative Models to Defend Membership Inference Attack"
collection: publications
permalink: /publication/2023-05-17-mixup
excerpt: 'With the popularity of machine learning, it has been a growing concern on the trained model revealing the private information of the training data. Membership inference attack (MIA) poses one of the threats by inferring whether a given sample participates in the training of the target model. Although MIA has been widely studied for discriminative models, for generative models, neither it nor its defense is extensively investigated. In this work, we propose a mixup training method for generative adversarial networks (GANs) as a defense against MIAs. Specifically, the original training data is replaced with their interpolations so that GANs would never overfit the original data. The intriguing part is an analysis from the hypothesis test perspective to theoretically prove our method could mitigate the AUC of the strongest likelihood ratio attack. Experimental results support that mixup training successfully defends the state-of-the-art MIAs for generative models, yet without model performance degradation or any additional training efforts, showing great promise to be deployed in practice.'
date: 2023-05-17
venue: 'IEEE International Conference on Computer Communications (INFOCOM)'
paperurl: '/files/paper_mixup.pdf'
citation: 'Zhe Ji; Qiansiqi Hu; Liyao Xiang*; Chenghu Zhou; &quot;Mixup Training for Generative Models to Defend Membership Inference Attacks&quot;, in Proc. IEEE International Conference on Computer Communications (INFOCOM), New York area, USA, May 17-20, 2023.'
---

<a href='/files/paper_mixup.pdf'>Download paper here</a>

With the popularity of machine learning, it has been a growing concern on the trained model revealing the private information of the training data. Membership inference attack (MIA) poses one of the threats by inferring whether a given sample participates in the training of the target model. Although MIA has been widely studied for discriminative models, for generative models, neither it nor its defense is extensively investigated. In this work, we propose a mixup training method for generative adversarial networks (GANs) as a defense against MIAs. Specifically, the original training data is replaced with their interpolations so that GANs would never overfit the original data. The intriguing part is an analysis from the hypothesis test perspective to theoretically prove our method could mitigate the AUC of the strongest likelihood ratio attack. Experimental results support that mixup training successfully defends the state-of-the-art MIAs for generative models, yet without model performance degradation or any additional training efforts, showing great promise to be deployed in practice.

Recommended citation: Zhe Ji; Qiansiqi Hu; Liyao Xiang*; Chenghu Zhou; "Mixup Training for Generative Models to Defend Membership Inference Attacks", in Proc. IEEE International Conference on Computer Communications (INFOCOM), New York area, USA, May 17-20, 2023.